from dotenv import load_dotenv
from langchain_community.document_loaders import PyPDFLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_chroma import Chroma
from langchain_openai import OpenAIEmbeddings
from langchain.retrievers.multi_query import MultiQueryRetriever
from langchain_openai import ChatOpenAI

import streamlit as st

load_dotenv()

#ì œëª©
st.title("ChatPDF")
st.write("---")

#íŒŒì¼ ì—…ë¡œë“œ
import pandas as pd
from io import StringIO

uploaded_file = st.file_uploader("Choose a file")
st.write("---")
#ì—…ë¡œë“œ ë˜ë©´ ë™ì‘í•˜ëŠ” ì½”ë“œ
if uploaded_file is not None:
    
    


#Loader
loader = PyPDFLoader("chatPdf/economic.pdf")
pages = loader.load_and_split()

#Split
text_splitter = RecursiveCharacterTextSplitter(
    # Set a really small chunk size, just to show.
    chunk_size=1000,
    chunk_overlap=20, #ê²¹ì¹˜ëŠ” ê¸€ìì •í•´ì„œ ë¬¸ë§¥
    length_function=len,
    is_separator_regex=False,
)
texts = text_splitter.split_documents(pages)

#Embedding

embeddings_model = OpenAIEmbeddings()
# load it into Chroma
db = Chroma.from_documents(texts, embeddings_model)

# chat

question = "ëª‡í˜ì´ì§€ì—ì„œ ì–´ë–¤ ìš©ì–´ë¥¼ ì„¤ëª…ì¤‘ì´ì•¼?"
llm = ChatOpenAI(temperature=0)
retriever_from_llm = MultiQueryRetriever.from_llm(
    retriever=db.as_retriever(), llm=llm
)

from langchain.chains import RetrievalQA
from langchain_community.chat_models import ChatOpenAI

# QA ì²´ì¸ êµ¬ì„±
qa_chain = RetrievalQA.from_chain_type(
    llm=llm,
    retriever=retriever_from_llm,
    return_source_documents=True  # âœ… ë³€ê²½
)

response = qa_chain.invoke({"query": question})
print("ğŸ“Œ ë‹µë³€:", response["result"])